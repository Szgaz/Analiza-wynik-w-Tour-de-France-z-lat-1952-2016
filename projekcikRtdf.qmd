---
title: "Projekt Tour de France"
author: "Kacper Gałan, Szymon Gazdowicz"
date: today
format: 
  html:
    warning: false
    message: false
    echo: false
    self-contained: true
editor: visual
---

## Analiza wyników Tour de France z lat 1952-2016

```{r}
library(readODS)
library(ggplot2)
library(tidyverse)
library(rstatix)
library(gtsummary)
library(rvest)
library(gt)
library(ggmap)
library(flextable)
library(gsubfn)
library(ggthemes)
library(plotly)
library(plyr)
library(groupdata2)
library(reactable)


dane = read_ods("C:\\Users\\gauan\\OneDrive\\Documents\\tour_de_france.ods")
```

### Wprowadzenie

```{r}
#| label: tbl-overall
#| tbl-cap: "Pierwszych sześć obserwacji zgromadzonych danych"
dane %>% 
  head() %>% 
  gt()
```

Przedstawiony zbiór (patrz @tbl-overall) zawiera podstawowe informacje dotyczące zawodów kolarskich *Tour de France,* organizowanych w latach 1952-2016. *Tour de France* to wieloetapowy wyścig kolarski organizowany najczęściej w lipcu, na terenie Francji oraz państw ościennych. Należy do cyklu *World Tour* [@tourde2022].

Prestiż tego wyścigu wiąże się z długą historią (jest to obecnie najstarszy wyścig kolarski), wielką tradycją oraz przede wszystkim skalą trudności. Szczególnie znanym momentem jest podjazd pod przełęcz *L'Alpe d'Huez (*patrz @fig-alpe) *:* długość podjazdu -- 13,8 km; średnie nachylenie 7,9% (maksymalne 12%), przewyższenie -- 1126 metrów.

[![Dolina L'Alpe d'Huez](PROJEKT/Lacets_AlpedHuez.jpg){#fig-alpe fig-align="center" width="347"}](https://fr.wikipedia.org/wiki/Mont%C3%A9e_de_l%27Alpe_d%27Huez)

### Analiza zgromadzonych informacji

#### Podstawowe statystyki opisowe

```{r}
#| label: tbl-opisowe
#| tbl-cap: Podstawowe funkcje statystyczne dla zadanego zbioru
dane %>% 
  select(`Średnie tempo(km/h) zwycięzcy `, `Łączny dystans(km) `, `Ukończyło wyścig `, `Liczba zgłoszeń ` ) %>% 
  get_summary_stats() %>% 
  select(Zmienna = variable, min, max, median, mean) %>% 
  gt() %>% 
  fmt_number(columns = 5, decimals = 2)

```

Analizę danego tematu należy zacząć od przedstawienia podstawowych informacji o tym zbiorze, co już pozwala zauważyć pierwsze związki czy obserwacje (patrz @tbl-opisowe). Przykładowo w kolumnach *median* (*ang.* mediana) i *mean* (*ang.* średnia arytmetyczna) widzimy jak niewielkie są odstępstwa miedzy tymi dwiema miarami.

#### Miasta początkowe wyścigu Tour de France

```{r}
#| label: tbl-country
#| tbl-cap: Państwa rozpoczynające Tour de France
dane %>% 
  select(`Państwo rozpoczęcia`) %>% 
  group_by(`Państwo rozpoczęcia`) %>% 
  dplyr::mutate("Suma" = n()) %>% 
  unique() %>% 
  flextable()
```

Jak widać na wykresie (patrz @tbl-country) nie można zakładać, że wyścig zawsze rozpoczyna się w Francji. Jeszcze lepiej widać to na poniższej mapie (patrz @fig-maps). Pokazuje to jak zróżnicowane geograficznie są omawiane rozgrywki.

```{r}
wektor1 = NULL
wektor2 = NULL
miasta = unique(dane[,9])

for(miasto in miasta){
  miasto = str_replace_all(miasto, " ", "_")
  miasto =str_replace_all(str_replace_all(miasto, "St\\.", "Saint"), "_","-")
  miasto = str_replace_all(miasto, "Brest", "Brest,_France")
   miasto = str_replace_all(miasto, "'s-Hertogenbosch", "%27s-Hertogenbosch")
   miasto = str_replace_all(miasto, "La-Barre-de-Monts", "La_Barre-de-Monts")
   miasto = str_replace_all(miasto, "Le-Puy-de-Fou", "Puy_du_Fou")
   miasto = str_replace_all(miasto, "Le-Havre", "Le_Havre")
   miasto = str_replace_all(miasto, "San-Sebastian", "San_Sebastián")
   miasto = str_replace_all(miasto, "Nancy", "Nancy,_France")
   miasto = str_replace_all(miasto, "Montreuil", "Montreuil,_Seine-Saint-Denis")
  result = paste("https://en.wikipedia.org/wiki/", miasto, sep = "")

  url = read_html(result)
  
  lat = url %>% 
    html_nodes("span.latitude") %>% 
    html_text()
  
  lat = str_replace_all(str_replace_all(lat[1], "[:punct:][:alpha:]", ""), "°", ".")
  lat = str_extract_all(lat[1], "\\d\\d\\.[:digit:][:digit:]?")
  lat = lat[[1]]
  
  wektor1 = append(wektor1,as.numeric(lat))
  
  lon = url %>% 
    html_nodes("span.longitude") %>% 
    html_text()
  
  if(grepl("W", lon[1], fixed = TRUE)){
    lon = paste("-", lon[1], sep="")
  }

  lon = str_replace_all(str_replace_all(lon[1], "[:punct:][:alpha:]", ""), "°", ".")
  lon = str_extract_all(lon, "\\-?\\d?\\d\\.\\d\\d?")
  
  wektor2 = append(wektor2,as.numeric(lon)) 
}

wspol = data.frame(x=wektor2,y=wektor1)
```

```{r}
#| label: fig-maps
#| fig-cap: Miasta początkowe na tle mapy Europy
ggmap::register_google(key = "AIzaSyDNq0npPq9JWzJM01_IElhpb8FWXM5zF_M", write = TRUE)


get_googlemap(center = "Le Havre", zoom = 5, markers = wspol) %>% 
  ggmap()

```

#### Kto jeździł najlepiej?

Na powyższe pytanie pomaga odpowiedzieć tabela niżej (patrz @tbl-thebest). Dzięki niej obserwujemy, że to **Irlandczycy** (!) średnio przejechali najwięcej, natomiast największe prędkości "kręcili" **Brytyjczycy**.

```{r}
#| label: tbl-thebest
#| tbl-cap: Wyniki poszczególnych zwycięskich narodowości
fajne = dane %>% 
  drop_na() %>% 
  group_by(`Narodowość zwycięzcy`) %>% 
  dplyr::mutate("Średni dystans" = mean(`Łączny dystans(km) `), "Średnia prędkość" = mean(`Średnie tempo(km/h) zwycięzcy `)) %>% 
  select(`Narodowość zwycięzcy`,"Średni dystans" ,"Średnia prędkość") %>% 
  unique() 

fajne %>%  
  mutate_if(is.numeric, round, digits = 2) %>% 
  flextable() %>% 
  add_header_row(colwidths = 3,
                 values = "Wyniki") %>% 
  theme_vanilla() %>% 
  add_footer_lines("Osiągi zwycięskich narodowości") %>% 
  color(part = "footer", color = "gray")


```

Rozkład średniego dystansu do średniej prędkości wizualizuje wykres @fig-thebest.

```{r}
#| label: fig-thebest
#| fig-cap: Wizualizacja osiągów poszczególnych zwycięskich narodowości
h = fajne %>% 
  ggplot()+
  geom_point(aes(x = `Średni dystans`, 
                 y = `Średnia prędkość`,
                 color = `Narodowość zwycięzcy`))

ggplotly(h)
```

Amerykanin dzięki środkom wydolnościowym jechał średnio **najszybciej** w toku całego turnieju w omawianych latach.

#### Stosunek zapisanych do tych którzy ukończyli konkurs

W kolumnie *Procent* poniższego wykresu wyrażony jest procentowy stosunek zmiennej *Liczba zgłoszeń* do *Ukończyło wyścig* w danych latach. Z tabeli (patrz @tbl-wyniki) nie zauważamy szczególnej korelacji między latami a omawianą zależnością.

```{r}
#| label: tbl-wyniki
#| tbl-cap: Procentowy stosunek zapisanych do finiszerów 
dane1 = dane
dane1$Rok= cut(dane1$Rok, breaks = 10)

dane1 %>% 
  group_by(Rok) %>%
  dplyr::mutate(zapisani = `Ukończyło wyścig `/`Liczba zgłoszeń `) %>% 
  select(Rok, zapisani) %>%
  group_by(Rok) %>%
  dplyr::mutate("Procent" = round(mean(zapisani)*100),2) %>% 
  select(Rok, "Procent") %>% 
  arrange(desc(Procent)) %>% 
  unique() %>% 
  flextable()

```

#### Liczba etapów a łączny dystans

Poniższy wykres wizualizuje stosunek zmiennej *Liczba etapów* do zmiennej *Łączny dystans(km)* w podziale na państwa, w których omawiany wyścig rozpoczął się przynajmniej dwa razy. Z grafiki odczytujemy ewidentną zależność - im więcej etapów tym dłuższy jest wyścig.

```{r}
#| label: fig-etapy
#| fig-cap: Liczba etapów a długość rejsu
mm = dane %>% 
  select(`Liczba etapów `, `Łączny dystans(km) `, `Państwo rozpoczęcia`) %>% 
  group_by(`Państwo rozpoczęcia`) %>% 
  dplyr::mutate(n=n()) 
  
elo = mm[which(mm[,4]>2),] %>% 
  ggplot(aes(`Liczba etapów `, `Łączny dystans(km) `, color = `Państwo rozpoczęcia`  ))+
  geom_point()+
  geom_smooth(method = lm, se = FALSE)+
  facet_wrap(~`Państwo rozpoczęcia`)
  

ggplotly(elo)
```

```{r}
library(Metrics)
library(dplyr)
library(lmtest)
library(car)
library(ggplot2)
library(olsrr)

dane = readODS::read_ods("tour_de_france_z_waga.ods")
dane_liczbowe = dane[, -c(1, 7,8,9,10, 13)]
dane_liczbowe$Wzrost = as.numeric(dane$Wzrost)
```

## Dobór oraz analiza modelu regresji liniowej

### Model na postawie korelacji

Na podstawie poznanych metod i wskaźników miar dopasowania postaramy się wybrać najlepszy model regresji. Rozpoczynamy od doboru zmiennych objaśniających na podstawie wartości korelacji liniowej.

```{r}
model_pelny = lm(`Średnie tempo(km/h) zwycięzcy `~., data = dane_liczbowe)
model_pusty = lm(`Średnie tempo(km/h) zwycięzcy `~1, data = dane_liczbowe)
#summary(model_pelny)
```

```{r}
library(PerformanceAnalytics)
chart.Correlation(dane_liczbowe)
```

Sugerując się wykresem korelacji odrzucamy z modelu zmienne: Waga oraz Wzrost. Budujemy model postaci:

```{r}
dane_liczbowe_istotne = dane_liczbowe[,-c(6, 7)]
#chart.Correlation(dane_liczbowe_istotne)
```

```{r}
model_nasz = lm(`Średnie tempo(km/h) zwycięzcy `~., data = dane_liczbowe_istotne)
#summary(model_nasz)
```

*Średnie tempo(km/h) zwycięzcy \~ Łączny dystans(km) + Liczba etapów + Ukończyło wyścig + Liczba zgłoszeń + Wiek*

Przeprowadzamy test ANOVA, aby porównać czy zbudowany powyżej model będzie lepszy od modelu pełnego (każda potencjalna zmienna jest zmienną objaśniającą).

```{r}
anova(model_pelny,model_nasz)
```

Według przeprowadzonego testu ANOVA lepszy jest model z mniejszą liczbą zmiennych.

## Model zbudowany metodą regresji krokowej (wg. indeksu AIC)

Tworzymy konkurencyjne modele zbudowane z użyciem regresji krokowej tworzonej za pomocą funkcji `step()`. W celu wybrania najbardziej optymalnego modelu sugerować się będziemy indeksem AIC.

Rozpoczynamy od budowy modelu metodą *forward*, przechodząc od modelu pustego (zawierającego jedynie wyraz wolny) dodając do niego potencjalne zmienne. Otrzymany model: *Średnie tempo(km/h) zwycięzcy \~ Wiek + Łączny dystans(km) + Liczba zgłoszeń + Waga + Wzrost*, dla którego otrzymany indeks AIC wynosi 18.62.

```{r}
#step(model_pusty, direction = "forward",scope = formula(model_pelny), test = "F")

model_wprzod = lm(`Średnie tempo(km/h) zwycięzcy ` ~ Wiek + `Łączny dystans(km) ` + 
    `Liczba zgłoszeń ` + Waga + Wzrost, data = dane_liczbowe)

#summary(model_wprzod)
```

Następnie sprawdzamy, czy model budowany metodą *backward*, czyli idąc od modelu pełnego odrzucamy zmienne, które zawyżają wartość indeksu AIC. Otrzymujemy dokładnie taki sam model jak zbudowany powyżej, z dokładnie takim samym indeksem AIC.

```{r}
#step(model_pelny, direction = "backward",scope = formula(model_pusty), test = "F")

model_wstecz = lm(`Średnie tempo(km/h) zwycięzcy ` ~ `Łączny dystans(km) ` + 
    `Liczba zgłoszeń ` + Waga + Wzrost + Wiek, data = dane_liczbowe)

#summary(model_wstecz)
```

Ostatecznie budujemy model, gdzie zmienne objaśniające są zarówno dodawane jak i odrzucane z modelu. Podobnie jak w poprzedniej sytuacji, dostajemy dentyczną podstać modelu.

```{r}
#step(model_pusty, direction = "both",scope = formula(model_pelny), test = "F")

model_both = lm(`Średnie tempo(km/h) zwycięzcy ` ~ `Łączny dystans(km) ` + 
    `Liczba zgłoszeń ` + Waga + Wzrost + Wiek, data = dane_liczbowe)

```

## Wybór ostatecznego modelu

O tym który model będzie ostatecznym modelem regresji, decydować będą wartości miar poasowania danych empirycznych do teoretycznych dla każdego z danych modli.

```{r}
library(kableExtra)
y = dane_liczbowe$`Średnie tempo(km/h) zwycięzcy `

PRESS = function(x, x_bar){
  return(sum((x - x_bar)^2))
}

Model_Nasz = c(Metrics::mae(y, model_nasz$fitted.values),
                 mse(y, model_nasz$fitted.values),
                 Metrics::rmse(y, model_nasz$fitted.values),
                 summary(model_nasz)$r.squared,
                 AIC(model_nasz),
                 BIC(model_nasz),
                 PRESS(y, model_nasz$fitted.values))

Model_Wprzod = c(Metrics::mae(y, model_wprzod$fitted.values),
                 mse(y, model_wprzod$fitted.values),
                 Metrics::rmse(y, model_wprzod$fitted.values),
                 summary(model_wprzod)$r.squared,
                 AIC(model_wprzod),
                 BIC(model_wprzod),
                 PRESS(y, model_wprzod$fitted.values))


df = data.frame(Model_Nasz, Model_Wprzod)
rownames(df) = c("MAE", "MSE", "RMSE", "R^2", "AIC", "BIC", "PRESS")

df = df %>% 
  mutate_if(is.numeric, round, 2)

kable(df) %>% kable_styling()
```

Na podstawie miar i kryteriów dopasowania danych empirycznych do teoretycznych wybieramy model zbudowany metodą regresji krokowej.

## Analiza modelu

### Liniowość

Sprawdzamy, czy istnieje liniowa zależność między zmiennymi objaśniającymi (X) a zmienną objaśnianą (Y).

```{r}
plot(model_wprzod, which = 1)
```

Powyższy wykres zależności wartości dopasowanych do reszt sugeruje brak liniowości analizowanego modelu.

```{r}
reset = resettest(model_wprzod)
rainbow = raintest(model_wprzod)
harv = harvtest(model_wprzod)
pv = c(reset$p.value, rainbow$p.value, harv$p.value)
n = c("Test Reset", "Test Rainbow", "Test Harvey'a-Collier'a")
liniowosc = data.frame(P_value = pv)
rownames(liniowosc) = n

```

```{r}
#| label: tbl-linearity
#| tbl-cap: P-values testów na liniowość
liniowosc %>% 
  kable %>% 
  kable_styling()
```

\
Ostatecznie jednak, w oparciu o powyższą tabelę (@tbl-linearity) odrzucamy początkowe wnioski wynikające z analizy wykresu wartości dopasowanych do reszt. Warunek liniowości jest spełniony.

### Homoskedastyczność

W oparciu o poniższy wykres pierwiastka ze standaryzowanych reszt względem wartości dopasowanych, zwracając uwagę na czerwono linię, możemy wnioskować o złamaniu warunku jednorodności reszt modelu. Tezę tę poprzemy (bądź obalimy) przeprowadzając test statystyczny *Breutsch'a-Pagan'a.*

```{r}
plot(model_wprzod, which = 3)
```

Otrzymane poniżej *p-value* nie daje nam jednak powodów do odrzucenia hipotezy od jednorodności reszt modelu. Warunek homoskedastyczności nie został złamany.

```{r}
round(bptest(model_wprzod)$p.value,2)
```

### Normalność reszt modelu

```{r}
#hist(model_wprzod$residuals)
#plot(model_wprzod, which = 2)

ggplot(dane_liczbowe,aes(model_wprzod$residuals)) +
  geom_histogram(binwidth = 0.5, fill = "purple", color = "black", boundary = 0.5)+
  labs(title = "Histogram Reszt Modelu",
       x = "Reszty", y = "Liczebność")
```

Powyższy histogram ilustruje rozkład reszt analizowanego modelu. Wnioskując z jego postaci, możemy mieć powody do wnioskowania o normalności rozkładu szumów modelu.

Poniższy test *Shapiro-Wilk'a* potwierdza naszą tezę - reszty zadanego modelu mają rozkład normalny.

```{r}
round(shapiro.test(model_wprzod$residuals)$p.value,2)
```
